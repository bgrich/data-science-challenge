---
title: "Variable Importance via Random Forest"
output: 
  html_notebook:
    toc: true
    toc_float: true
---

```{r setup, message = FALSE}
library(tidyverse)
library(jsonlite)
library(caret)

report_theme <- ggplot2::theme_bw() +
  ggplot2::theme(panel.border = ggplot2::element_rect(color = "black",
                                                      fill = NA),
                 panel.grid.major = ggplot2::element_line(color = "black",
                                                          linetype = "dotted"),
                 panel.grid.minor = ggplot2::element_line(color = "black",
                                                          linetype = "dotted"))
```

In this notebook, I plan to use a random forest algorithm to determine the 
importance of the variables in the data set. The variables I will be using 
are: 

* Referral Time (ts_referral) 
* Lead Time (ts_lead) 
* Check-in Difference
* Check-out Difference
* Lead Rate Partner
* Referral Rate Partner
* Same Partner Conditional 
* location-tid
* udicode

# Data Import and Preparation

First, I need to import and prepare the data for analysis.

```{r, message = FALSE}
room_key_data <- read_tsv("data.tsv", progress = FALSE) %>% 
  rownames_to_column() %>% 
  rename(key = rowname) %>% 
  mutate(lead_event = !(lead == "null"), 
         booking_event = !(booking == "null"))
```

```{r}
referral_key <- room_key_data %>% 
  filter(referral != "null") %>% 
  select(key, lead_event, booking_event)

referral <- room_key_data %>% 
  filter(referral != "null") %>%
  .$referral %>% 
  map_df(fromJSON) %>% 
  bind_cols(referral_key) %>% 
  select(key, everything()) %>% 
  rename(visitor_id = `visitor-id`, 
         event_id_referral = `event-id`, 
         ts_referral = ts,
         location_tid = `location-tid`, 
         partner_code = `partner-code`, 
         check_in = `check-in`, 
         check_out = `check-out`)
```

```{r}
lead_key <- room_key_data %>% 
  filter(lead != "null") %>% 
  select(key, booking_event)

lead <- room_key_data %>% 
  filter(lead != "null") %>%
  .$lead %>% 
  map_df(fromJSON) %>% 
  bind_cols(lead_key) %>% 
  select(key, everything()) %>% 
  rename(visitor_id = `visitor-id`, 
         event_id_lead = `event-id`, 
         ts_lead = ts, 
         rate_partner = `rate-partner`)
```

```{r}
booking_key <- room_key_data %>% 
  filter(booking != "null") %>% 
  select(key)

booking <- room_key_data %>% 
  filter(booking != "null") %>%
  .$booking %>%  
  map_df(fromJSON) %>% 
  bind_cols(booking_key) %>% 
  select(key, everything())
```

## Preparation

Here I want to combine some information from the referral data set into the 
lead data set. As part of this, I also rename a few columns and convert 
some of the columns to different data types. Specifically, the check_in and 
check_out columns are converted to dates. Unlike the previous work, the ts 
(timestamp) columns are left in units of milliseconds. 

```{r}
referral_info <- referral %>% 
  filter(lead_event == TRUE) %>% 
  select(-event_id_referral, -type, -lead_event, -booking_event)

lead_ref <- lead %>% 
  select(-event_id_lead, - type) %>% 
  left_join(referral_info, by = c("key", "visitor_id")) %>% 
  rename(rate_partner_lead = rate_partner, 
         partner_code_referral = partner_code) %>% 
  mutate(check_in = lubridate::ymd(check_in), 
         check_out = lubridate::ymd(check_out), 
         check_in_diff = as.numeric(check_in - lubridate::ymd("2017-10-15")), 
         check_out_diff = as.numeric(check_out - lubridate::ymd("2017-10-15")))
```

# Random Forest

First, I want to set up the data for the random forest model. I want to split 
the data into testing and training sets for comparison after running the model. 
I also want to look at the number of NAs present in the data. I plan on 
running the model with a few different variations. Once with all of the data, 
again with the NA's removed, and again with certain variables removed. 

```{r}
data_for_model <- lead_ref %>% 
  select(booking_event, 
         ts_lead, 
         ts_referral, 
         check_in_diff, 
         check_out_diff, 
         partner_code_referral, 
         rate_partner_lead, 
         location_tid, 
         udicode)
```

## NAs

Here, I calculate the number of NAs in the data set.

```{r}
lead_ref %>% 
  select(-key, -visitor_id, -booking_event, -check_out_diff, -check_in_diff) %>% 
  map_dbl(function(x) sum(is.na(x)))
```

There are about 4500 NAs in the check-in and check-out information. There are 
a smaller number in the ts_referral, location_tid, and partner_code_referral 
variables. There are a large number of NA's (approximate 10k) in the udicode 
variable.

## Train/Test Split

Now I will randomly split the data into testing and training subsets using an 
80/20 training/testing split. For this, I will set the random seed for R so 
that the results are reproducibile. 

```{r}
set.seed(85)

train_index <- createDataPartition(data_for_model$booking_event, 
                            p = 0.8,
                            list = FALSE, 
                            times = 1)

training <- data_for_model[train_index, ]
testing <- data_for_model[-train_index, ]
```

